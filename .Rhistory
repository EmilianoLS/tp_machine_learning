plot(cars)
rm(list = ls())
setwd('C:/Users/tutif/desktop/emi/tp_machine_learning')
source('functions_R.R')
#  busco librerias a usar y asigno la ruta en github
rm(list = ls())
setwd('D:/DS_Projects/tp_machine_learning')
#setwd('C:/Users/elosasso/OneDrive - Universidad Torcuato Di Tella/Machine Learning/TP/script/tp_machine_learning')
#setwd('C:/Users/tutif/Desktop/emi/tp_machine_learning')
source('functions_R.R')
Ruta <- "https://raw.githubusercontent.com/EmilianoLS/tp_machine_learning/master/train.csv"
data <- read_csv(url(Ruta))
data$TARGET <- factor(if_else(data$TARGET == 1, 'churn', 'no_churn'))
# Veo como se estructuran los datos
head(data)
dim(data)
# Clases de variables
table(sapply(data, class))
# Creo un vector con las columnas para castear
bool_columns <- names(data)[grepl("ind", names(data))]
# Hago el cast
data[bool_columns] <- lapply(data[bool_columns], as.logical)
# Vuelvo a chequear las clases de variables
table(sapply(data, class))
histplot <- ggplot(data) + geom_histogram(aes(x = data$age), bins = 100) +
geom_vline(aes(xintercept = mean(data$age)), colour = 'red',linetype = "longdash") +
geom_vline(aes(xintercept = median(data$age)), colour = 'blue', linetype = 'longdash') +
annotate('text',x = mean(data$age)+10, y = 2000, label = 'Promedio', colour = 'red') +
annotate('text',x = median(data$age)-10, y = 4000, label = 'Media', colour = 'blue') +
ggtitle('Distribución de la edad') + xlab('Edad')
caja <- ggplot(data) + geom_boxplot(aes(x = age)) + ggtitle('Distribución de la edad') + xlab('Edad')
grid.arrange(histplot, caja, ncol = 1)
ages <- as.data.frame(table(data$age))
order.age <- order(ages$Freq, decreasing = TRUE)
ages <- ages[order.age, ]
ages[c(1:5),]
cat('Edad mínima:', min(data$age), '\nEdad máxima:', max(data$age))
data %>% ggplot(aes(x = age, fill = TARGET)) + geom_histogram(color="#e9ecef", alpha=0.4, position = 'identity', bins = 50) + ggtitle('Distribución de la edad según el target')
ggplot(data, aes(TARGET)) + geom_bar() + ggtitle('Proporción de churn/no churn')
prop.table(table(data$TARGET))
plot1 <- data %>% ggplot(aes(x = var21, fill = TARGET)) + geom_histogram(color="#e9ecef", alpha=0.4, position = 'identity', bins = 50) + ggtitle('Distribución de la var21 según el target')
plot2 <- data %>% ggplot(aes(x = var36, fill = TARGET)) + geom_histogram(color="#e9ecef", alpha=0.4, position = 'identity', bins = 50) + ggtitle('Distribución de la var36 según el target')
plot3 <- data %>% ggplot(aes(x = var38, fill = TARGET)) + geom_histogram(color="#e9ecef", alpha=0.4, position = 'identity', bins = 50) + ggtitle('Distribución de la var38 según el target')
ggarrange(plot1,plot2,plot3,ncol = 1)
# Miro los quantiles para ver qué tanto varían los datos
quantile(data$var21)
quantile(data$var36)
quantile(data$var38)
# Var36 y 38 parecen mostrar datos más distribuidos, pero var21 pareciera solamente tener dos valores: 0 y 30000
# Distribución de var21 para valores superiores a 0
data$temp <- if_else(data$var21 > 0, 'mayor_0','igual_0')
plot1 <- filter(data,var21 > 0) %>% ggplot(aes(x = var21, fill = TARGET)) + geom_histogram(color="#e9ecef", alpha=0.4, position = 'identity', bins = 50) + ggtitle('Distribución de la var21 según el target')
plot2 <- ggplot(data, aes(temp)) + geom_bar() + ggtitle('Proporción de var21 mayor a 0')
ggarrange(plot1,plot2, ncol = 1)
data$temp <- NULL
# Busco todos los nulos
sum(is.na(data))
# Llamo a una función para encontrar la proporción nulos por columna
find_nulls(data)
# Eliminamos los nulos
data <- drop_na(data)
dim(data)
# Seteo una semilla para recrear las distintas pruebas
set.seed(999)
# Selecciono los indices de entrenamiento
inTraining <- createDataPartition(data$TARGET, p = .75, list = FALSE)
# Separo los dos conjuntos de datos
train_data <- data[inTraining, ]
validation_data <- data[-inTraining, ]
# Verifico que ambos conjuntos estén balanceados
print('Distribucion del target en el conjunto de entrenamiento')
prop.table(table(train_data$TARGET))
print('Distribucion del target en el conjunto de validacion')
prop.table(table(validation_data$TARGET))
# Entrenamos el modelo Arbol
fitControl <- trainControl(method = 'cv',
number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary)
rpartFit <- train(TARGET ~ .,data = train_data,
method = 'rpart',
trControl = fitControl,
metric = 'ROC')
#bechmark_result <- max(rpartFit$result
max(rpartFit$results$ROC)
#  busco librerias a usar y asigno la ruta en github
#rm(list = ls())
setwd('D:/DS_Projects/tp_machine_learning')
#setwd('C:/Users/elosasso/OneDrive - Universidad Torcuato Di Tella/Machine Learning/TP/script/tp_machine_learning')
#setwd('C:/Users/tutif/Desktop/emi/tp_machine_learning')
source('functions_R.R')
Ruta <- "https://raw.githubusercontent.com/EmilianoLS/tp_machine_learning/master/train.csv"
#  busco librerias a usar y asigno la ruta en github
#rm(list = ls())
setwd('D:/DS_Projects/tp_machine_learning')
#setwd('C:/Users/elosasso/OneDrive - Universidad Torcuato Di Tella/Machine Learning/TP/script/tp_machine_learning')
#setwd('C:/Users/tutif/Desktop/emi/tp_machine_learning')
source('functions_R.R')
Ruta <- "https://raw.githubusercontent.com/EmilianoLS/tp_machine_learning/master/train.csv"
resultados <- predict_function(rpartFit,validation_data,'TARGET')
# Entrenamos el modelo Arbol
######################################  MODELO BENCHMARK  ######################################
fitControl <- trainControl(method = 'cv',
number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary)
rpartFit <- train(TARGET ~ .,data = train_data,
method = 'rpart',
trControl = fitControl,
metric = 'ROC')
bechmark_result <- max(rpartFit$results$ROC)                            # Guardo resultados del entrenamiento
# Evaluamos en Test
pred <- predict(rpartFit,validation_data, type = 'prob')
pred$pred <- factor(if_else(pred$churn >= .5, 'churn','no_churn'))
pred$obs <- validation_data$TARGET
test_results_benchmark <- twoClassSummary(pred, lev = levels(pred$obs))
test_results_benchmark <- as.numeric(test_results_benchmark[1])         # Guardo resultados de testing
test_results_benchmark
# Entrenamos el modelo Arbol
######################################  MODELO BENCHMARK  ######################################
fitControl <- trainControl(method = 'cv',
number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary)
rpartFit <- train(TARGET ~ .,data = train_data,
method = 'rpart',
trControl = fitControl,
metric = 'ROC')
train_bechmark_result <- max(rpartFit$results$ROC)                            # Guardo resultados del entrenamiento
# Evaluamos en Test
pred <- predict(rpartFit,validation_data, type = 'prob')
pred$pred <- factor(if_else(pred$churn >= .5, 'churn','no_churn'))
pred$obs <- validation_data$TARGET
test_results_benchmark <- twoClassSummary(pred, lev = levels(pred$obs))
test_results_benchmark_roc <- as.numeric(test_results_benchmark[1])         # Guardo resultados de testing
######################################  MODELO LOG TRF  ######################################
test_results_benchmark
test_results_benchmark_roc
# Entrenamos el modelo Arbol
######################################  MODELO BENCHMARK  ######################################
fitControl <- trainControl(method = 'cv',
number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary)
rpartFit <- train(TARGET ~ .,data = train_data,
method = 'rpart',
trControl = fitControl,
metric = 'ROC')
train_bechmark_result <- max(rpartFit$results$ROC)                            # Guardo resultados del entrenamiento
# Evaluamos en Test
pred <- predict(rpartFit,validation_data, type = 'prob')
pred$pred <- factor(if_else(pred$churn >= .5, 'churn','no_churn'))
pred$obs <- validation_data$TARGET
test_results_benchmark <- twoClassSummary(pred, lev = levels(pred$obs))
test_results_benchmark_roc <- as.numeric(test_results_benchmark[1])         # Guardo resultados de testing
###########################################  MODELO LOG TRF  ######################################
# Transformación logarítmica de los datos
train_data_log <- log_function(train_data, 'TARGET')      # Función definida que aplica la transformación logarítmica sobre los datos numéricos
validation_data_log <- log_function(validation_data, 'TARGET')
# Entrenamos el modelo
rpartFit_log <- train(TARGET ~ .,data = train_data_log,
method = 'rpart',
trControl = fitControl,
metric = 'ROC')
train_logtf_result <- max(rpartFit_log$results$ROC)
# Entrenamos el modelo Arbol
######################################  MODELO BENCHMARK  ######################################
fitControl <- trainControl(method = 'cv',
number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary)
rpartFit <- train(TARGET ~ .,data = train_data,
method = 'rpart',
trControl = fitControl,
metric = 'ROC')
train_bechmark_result <- max(rpartFit$results$ROC)                            # Guardo resultados del entrenamiento
# Evaluamos en Test
pred <- predict(rpartFit,validation_data, type = 'prob')
pred$pred <- factor(if_else(pred$churn >= .5, 'churn','no_churn'))
pred$obs <- validation_data$TARGET
test_results_benchmark <- twoClassSummary(pred, lev = levels(pred$obs))
test_results_benchmark_roc <- as.numeric(test_results_benchmark[1])         # Guardo resultados de testing
###########################################  MODELO LOG TRF  ######################################
# Transformación logarítmica de los datos
train_data_log <- log_function(train_data, 'TARGET')      # Función definida que aplica la transformación logarítmica sobre los datos numéricos
validation_data_log <- log_function(validation_data, 'TARGET')
# Entrenamos el modelo
rpartFit_log <- train(TARGET ~ .,data = train_data_log,
method = 'rpart',
trControl = fitControl,
metric = 'ROC')
train_logtf_result <- max(rpartFit_log$results$ROC)
# Evaluamos en Test
pred <- predict(rpartFit_log,validation_data_log, type = 'prob')
pred$pred <- factor(if_else(pred$churn >= .5, 'churn','no_churn'))
pred$obs <- validation_data_log$TARGET
test_results_log <- twoClassSummary(pred, lev = levels(pred$obs))
test_results_log_roc <- as.numeric(test_results_log[1])
###########################################  MODELO NORMALIZADO  ######################################
# Normalizamos los datos con la función preProcess
preprocess_norm <- preProcess(train_data, norm = c('center','scale'))
# Aplicamos el modelo aprendido al conjunto de entrenamiento y validación
# Guardamos en otra variable para no perder la original
train_data_norm <- predict(preprocess_norm, train_data)
validation_data_norm <- predict(preprocess_norm, validation_data)
# Entrenamos el modelo
rpartFit_norm <- train(TARGET ~ .,data = train_data_norm,
method = 'rpart',
trControl = fitControl,
metric = 'ROC')
train_norm_result <- max(rpartFit_norm$results$ROC)
# Evaluamos en Test
pred <- predict(rpartFit_norm,validation_data_norm, type = 'prob')
pred$pred <- factor(if_else(pred$churn >= .5, 'churn','no_churn'))
pred$obs <- validation_data_norm$TARGET
test_results_norm <- twoClassSummary(pred, lev = levels(pred$obs))
test_results_norm_roc <- as.numeric(test_results_norm[1])
######################################  MODELO NORMALIZADO + LOG TRF  ######################################
# Aplicamos una transformación log y normalizamos los datos
preprocess_norm_log <- preProcess(train_data_log, norm = c('center','scale'))
# Aplico el modelo aprendido sobre los conjuntos de entrenamiento y validación
train_data_log_norm <- predict(preprocess_norm_log, train_data_log)
validation_data_log_norm <- predict(preprocess_norm_log, validation_data_log)
# Entrenamos el modelo
rpartFit_log_norm <- train(TARGET ~ .,data = train_data_log_norm,
method = 'rpart',
trControl = fitControl,
metric = 'ROC')
train_log_norm_result <- max(rpartFit_log_norm$results$ROC)
# Evaluamos en Test
pred <- predict(rpartFit_log_norm,validation_data_log_norm, type = 'prob')
pred$pred <- factor(if_else(pred$churn >= .5, 'churn','no_churn'))
pred$obs <- validation_data_log_norm$TARGET
test_results_log_norm <- twoClassSummary(pred, lev = levels(pred$obs))
test_results_log_norm_roc <- as.numeric(test_results_log_norm[1])
######################################  TABLA FINAL CON LOS RESULTADOS  ######################################
modelos <- c('Benchmark','Transformación log','Normalizado','Ambas transformaciones')
resultados_training <- c(train_bechmark_result,train_logtf_result,train_norm_result,train_log_norm_result)
resultados_validation <- c(test_results_benchmark_roc,test_results_log_roc,test_results_norm_roc,test_results_log_norm_roc)
data.frame(modelos,resultados_training,resultados_validation)
#  busco librerias a usar y asigno la ruta en github
rm(list = ls())
setwd('D:/DS_Projects/tp_machine_learning')
#setwd('C:/Users/elosasso/OneDrive - Universidad Torcuato Di Tella/Machine Learning/TP/script/tp_machine_learning')
#setwd('C:/Users/tutif/Desktop/emi/tp_machine_learning')
source('functions_R.R')
Ruta <- "https://raw.githubusercontent.com/EmilianoLS/tp_machine_learning/master/train.csv"
data <- read_csv(url(Ruta))
data$TARGET <- factor(if_else(data$TARGET == 1, 'churn', 'no_churn'))
# Veo como se estructuran los datos
head(data)
dim(data)
# Clases de variables
table(sapply(data, class))
# Creo un vector con las columnas para castear
bool_columns <- names(data)[grepl("ind", names(data))]
# Hago el cast
data[bool_columns] <- lapply(data[bool_columns], as.logical)
# Vuelvo a chequear las clases de variables
table(sapply(data, class))
histplot <- ggplot(data) + geom_histogram(aes(x = data$age), bins = 100) +
geom_vline(aes(xintercept = mean(data$age)), colour = 'red',linetype = "longdash") +
geom_vline(aes(xintercept = median(data$age)), colour = 'blue', linetype = 'longdash') +
annotate('text',x = mean(data$age)+10, y = 2000, label = 'Promedio', colour = 'red') +
annotate('text',x = median(data$age)-10, y = 4000, label = 'Media', colour = 'blue') +
ggtitle('Distribución de la edad') + xlab('Edad')
caja <- ggplot(data) + geom_boxplot(aes(x = age)) + ggtitle('Distribución de la edad') + xlab('Edad')
grid.arrange(histplot, caja, ncol = 1)
ages <- as.data.frame(table(data$age))
order.age <- order(ages$Freq, decreasing = TRUE)
ages <- ages[order.age, ]
ages[c(1:5),]
cat('Edad mínima:', min(data$age), '\nEdad máxima:', max(data$age))
data %>% ggplot(aes(x = age, fill = TARGET)) + geom_histogram(color="#e9ecef", alpha=0.4, position = 'identity', bins = 50) + ggtitle('Distribución de la edad según el target')
ggplot(data, aes(TARGET)) + geom_bar() + ggtitle('Proporción de churn/no churn')
prop.table(table(data$TARGET))
plot1 <- data %>% ggplot(aes(x = var21, fill = TARGET)) + geom_histogram(color="#e9ecef", alpha=0.4, position = 'identity', bins = 50) + ggtitle('Distribución de la var21 según el target')
plot2 <- data %>% ggplot(aes(x = var36, fill = TARGET)) + geom_histogram(color="#e9ecef", alpha=0.4, position = 'identity', bins = 50) + ggtitle('Distribución de la var36 según el target')
plot3 <- data %>% ggplot(aes(x = var38, fill = TARGET)) + geom_histogram(color="#e9ecef", alpha=0.4, position = 'identity', bins = 50) + ggtitle('Distribución de la var38 según el target')
ggarrange(plot1,plot2,plot3,ncol = 1)
# Miro los quantiles para ver qué tanto varían los datos
quantile(data$var21)
quantile(data$var36)
quantile(data$var38)
# Var36 y 38 parecen mostrar datos más distribuidos, pero var21 pareciera solamente tener dos valores: 0 y 30000
# Distribución de var21 para valores superiores a 0
data$temp <- if_else(data$var21 > 0, 'mayor_0','igual_0')
plot1 <- filter(data,var21 > 0) %>% ggplot(aes(x = var21, fill = TARGET)) + geom_histogram(color="#e9ecef", alpha=0.4, position = 'identity', bins = 50) + ggtitle('Distribución de la var21 según el target')
plot2 <- ggplot(data, aes(temp)) + geom_bar() + ggtitle('Proporción de var21 mayor a 0')
ggarrange(plot1,plot2, ncol = 1)
data$temp <- NULL
# Busco todos los nulos
sum(is.na(data))
# Llamo a una función para encontrar la proporción nulos por columna
find_nulls(data)
# Eliminamos los nulos
data <- drop_na(data)
dim(data)
# Seteo una semilla para recrear las distintas pruebas
set.seed(999)
# Selecciono los indices de entrenamiento
inTraining <- createDataPartition(data$TARGET, p = .75, list = FALSE)
# Separo los dos conjuntos de datos
train_data <- data[inTraining, ]
validation_data <- data[-inTraining, ]
# Verifico que ambos conjuntos estén balanceados
print('Distribucion del target en el conjunto de entrenamiento')
prop.table(table(train_data$TARGET))
print('Distribucion del target en el conjunto de validacion')
prop.table(table(validation_data$TARGET))
# Entrenamos el modelo Arbol
######################################  MODELO BENCHMARK  ######################################
fitControl <- trainControl(method = 'cv',
number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary)
rpartFit <- train(TARGET ~ .,data = train_data,
method = 'rpart',
trControl = fitControl,
metric = 'ROC')
train_bechmark_result <- max(rpartFit$results$ROC)                            # Guardo resultados del entrenamiento
# Evaluamos en Test
pred <- predict(rpartFit,validation_data, type = 'prob')
pred$pred <- factor(if_else(pred$churn >= .5, 'churn','no_churn'))
pred$obs <- validation_data$TARGET
test_results_benchmark <- twoClassSummary(pred, lev = levels(pred$obs))
test_results_benchmark_roc <- as.numeric(test_results_benchmark[1])         # Guardo resultados de testing
###########################################  MODELO LOG TRF  ######################################
# Transformación logarítmica de los datos
train_data_log <- log_function(train_data, 'TARGET')      # Función definida que aplica la transformación logarítmica sobre los datos numéricos
validation_data_log <- log_function(validation_data, 'TARGET')
# Entrenamos el modelo
rpartFit_log <- train(TARGET ~ .,data = train_data_log,
method = 'rpart',
trControl = fitControl,
metric = 'ROC')
train_logtf_result <- max(rpartFit_log$results$ROC)
# Evaluamos en Test
pred <- predict(rpartFit_log,validation_data_log, type = 'prob')
pred$pred <- factor(if_else(pred$churn >= .5, 'churn','no_churn'))
pred$obs <- validation_data_log$TARGET
test_results_log <- twoClassSummary(pred, lev = levels(pred$obs))
test_results_log_roc <- as.numeric(test_results_log[1])
###########################################  MODELO NORMALIZADO  ######################################
# Normalizamos los datos con la función preProcess
preprocess_norm <- preProcess(train_data, norm = c('center','scale'))
# Aplicamos el modelo aprendido al conjunto de entrenamiento y validación
# Guardamos en otra variable para no perder la original
train_data_norm <- predict(preprocess_norm, train_data)
validation_data_norm <- predict(preprocess_norm, validation_data)
# Entrenamos el modelo
rpartFit_norm <- train(TARGET ~ .,data = train_data_norm,
method = 'rpart',
trControl = fitControl,
metric = 'ROC')
train_norm_result <- max(rpartFit_norm$results$ROC)
# Evaluamos en Test
pred <- predict(rpartFit_norm,validation_data_norm, type = 'prob')
pred$pred <- factor(if_else(pred$churn >= .5, 'churn','no_churn'))
pred$obs <- validation_data_norm$TARGET
test_results_norm <- twoClassSummary(pred, lev = levels(pred$obs))
test_results_norm_roc <- as.numeric(test_results_norm[1])
######################################  MODELO NORMALIZADO + LOG TRF  ######################################
# Aplicamos una transformación log y normalizamos los datos
preprocess_norm_log <- preProcess(train_data_log, norm = c('center','scale'))
# Aplico el modelo aprendido sobre los conjuntos de entrenamiento y validación
train_data_log_norm <- predict(preprocess_norm_log, train_data_log)
validation_data_log_norm <- predict(preprocess_norm_log, validation_data_log)
# Entrenamos el modelo
rpartFit_log_norm <- train(TARGET ~ .,data = train_data_log_norm,
method = 'rpart',
trControl = fitControl,
metric = 'ROC')
train_log_norm_result <- max(rpartFit_log_norm$results$ROC)
# Evaluamos en Test
pred <- predict(rpartFit_log_norm,validation_data_log_norm, type = 'prob')
pred$pred <- factor(if_else(pred$churn >= .5, 'churn','no_churn'))
pred$obs <- validation_data_log_norm$TARGET
test_results_log_norm <- twoClassSummary(pred, lev = levels(pred$obs))
test_results_log_norm_roc <- as.numeric(test_results_log_norm[1])
######################################  TABLA FINAL CON LOS RESULTADOS  ######################################
modelos <- c('Benchmark','Transformación log','Normalizado','Ambas transformaciones')
resultados_training <- c(train_bechmark_result,train_logtf_result,train_norm_result,train_log_norm_result)
resultados_validation <- c(test_results_benchmark_roc,test_results_log_roc,test_results_norm_roc,test_results_log_norm_roc)
data.frame(modelos,resultados_training,resultados_validation)
pred <- predict(rpartFit,validation_data, type = 'prob')[,2]
pred2 <- prediction(pred, validation_data$TARGET)
perf <- performance(pred2,"tpr","fpr")
# Graficamos la curva ROC
plot(perf, main="Curva ROC", colorize=T)
# Graficamos todas las curvas ROC
# Modelo Benchmark
pred <- predict(rpartFit,validation_data, type = 'prob')[,2]
pred2 <- prediction(pred, validation_data$TARGET)
perf <- performance(pred2,"tpr","fpr")
# Modelo log trf
pred_log <- predict(rpartFit_log,validation_data_log, type = 'prob')[,2]
pred2_log <- prediction(pred_log, validation_data_log$TARGET)
perf_log <- performance(pred2_log,"tpr","fpr")
# Modelo normalizado
pred_norm <- predict(rpartFit_norm,validation_data_norm, type = 'prob')[,2]
pred2_norm <- prediction(pred_norm, validation_data_norm$TARGET)
perf_norm <- performance(pred2_norm,"tpr","fpr")
# Modelo mixeado
pred_log_norm <- predict(rpartFit_log_norm,validation_data_log_norm, type = 'prob')[,2]
pred2_log_norm <- prediction(pred_log_norm, validation_data_log_norm$TARGET)
perf_log_norm <- performance(pred2_log_norm,"tpr","fpr")
# Graficamos la curva ROC
par(mfrow = c(2,2))
plot(perf, main="Curva ROC", colorize=T)
plot(perf_log, main="Curva ROC", colorize=T)
plot(perf_norm, main="Curva ROC", colorize=T)
plot(perf_log_norm, main="Curva ROC", colorize=T)
# Graficamos todas las curvas ROC
# Modelo Benchmark
pred <- predict(rpartFit,validation_data, type = 'prob')[,2]
pred2 <- prediction(pred, validation_data$TARGET)
perf <- performance(pred2,"tpr","fpr")
# Modelo log trf
pred_log <- predict(rpartFit_log,validation_data_log, type = 'prob')[,2]
pred2_log <- prediction(pred_log, validation_data_log$TARGET)
perf_log <- performance(pred2_log,"tpr","fpr")
# Modelo normalizado
pred_norm <- predict(rpartFit_norm,validation_data_norm, type = 'prob')[,2]
pred2_norm <- prediction(pred_norm, validation_data_norm$TARGET)
perf_norm <- performance(pred2_norm,"tpr","fpr")
# Modelo mixeado
pred_log_norm <- predict(rpartFit_log_norm,validation_data_log_norm, type = 'prob')[,2]
pred2_log_norm <- prediction(pred_log_norm, validation_data_log_norm$TARGET)
perf_log_norm <- performance(pred2_log_norm,"tpr","fpr")
# Graficamos la curva ROC
par(mfrow = c(2,2))
plot(perf, main="Curva ROC - Modelo Benchmark", colorize=T)
plot(perf_log, main="Curva ROC - Modelo log", colorize=T)
plot(perf_norm, main="Curva ROC - Modelo normalizado", colorize=T)
plot(perf_log_norm, main="Curva ROC - Modelo mix", colorize=T)
par(mfrow = c(1,2))
plot(varImp(rpartFit), top = 30, main = 'Feature Importance - Modelo Benchmark')
plot(varImp(rpartFit_log), top = 30, main = 'Feature Importance - Modelo Benchmark')
par(mfrow = c(1,2))
plot(varImp(rpartFit), top = 30, main = 'Feature Importance - Modelo Benchmark')
plot(varImp(rpartFit_log), top = 30, main = 'Feature Importance - Modelo Log')
# Open a pdf file
pdf("rplot.pdf")
par(mfrow = c(1,2))
plot(varImp(rpartFit), top = 30, main = 'Feature Importance - Modelo Benchmark')
plot(varImp(rpartFit_log), top = 30, main = 'Feature Importance - Modelo Log')
dev.off()
# Open a pdf file
pdf("rplot.pdf")
par(mfrow = c(2,2))
plot(varImp(rpartFit), top = 30, main = 'Feature Importance - Modelo Benchmark')
plot(varImp(rpartFit_log), top = 30, main = 'Feature Importance - Modelo Log')
plot(varImp(rpartFit_norm), top = 30, main = 'Feature Importance - Modelo Normalizado')
plot(varImp(rpartFit_log_norm), top = 30, main = 'Feature Importance - Modelo Mix')
dev.off()
# Open a pdf file
pdf("var_importance_rpart.pdf")
par(mfrow = c(2,2))
plot(varImp(rpartFit), top = 30, main = 'Feature Importance - Modelo Benchmark')
plot(varImp(rpartFit_log), top = 30, main = 'Feature Importance - Modelo Log')
plot(varImp(rpartFit_norm), top = 30, main = 'Feature Importance - Modelo Normalizado')
plot(varImp(rpartFit_log_norm), top = 30, main = 'Feature Importance - Modelo Mix')
dev.off()
